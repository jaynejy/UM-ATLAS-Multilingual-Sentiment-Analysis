{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**UM-ATLAS Sentiment Analysis Pipeline**\n",
        "1) Upload raw_mixed_feedback.xlsx (no labels) -> clean -> export clean_mixed_feedback.xlsx\n",
        "2) Upload labelled_mixed_feedback.xlsx (annotated clean_mixed_feedback.xlsx)\n",
        "3) Run this script in TRAIN mode:\n",
        "   - Load labelled_mixed_feedback.xlsx\n",
        "   - Validate labels (sentiment or numeric label)\n",
        "   - Split into train/val/test (non-overlapping, stratified)\n",
        "   - Train XLM-R, evaluate on val+test, save reports + model zip"
      ],
      "metadata": {
        "id": "Z-NDKTgRCYbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) Install dependencies\n",
        "!pip -q install -U transformers datasets evaluate scikit-learn numpy openpyxl \"pandas==2.2.2\""
      ],
      "metadata": {
        "id": "wopCdfFy7AqC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W2lP6sd-LTjO"
      },
      "outputs": [],
      "source": [
        "# 1) Imports\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import shutil\n",
        "import random\n",
        "import unicodedata\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import evaluate\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        "    EarlyStoppingCallback,\n",
        ")\n",
        "\n",
        "# Avoid Weights & Biases prompts (extra safety: TrainingArguments.report_to=\"none\" below)\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) CONFIG\n",
        "# Files\n",
        "RAW_INPUT_XLSX = \"/content/raw_mixed_feedback.xlsx\"\n",
        "CLEANED_EXPORT_XLSX = \"/content/clean_mixed_feedback.xlsx\"\n",
        "LABELLED_INPUT_XLSX = \"/content/(5025) labelled_mixed_feedback.xlsx\"\n",
        "\n",
        "# -------------------------\n",
        "# Auto column detection\n",
        "# -------------------------\n",
        "AUTO_DETECT_COLUMNS = True\n",
        "\n",
        "# Try these names first\n",
        "TEXT_COL_CANDIDATES = [\"clean_text\", \"text\", \"comment\", \"comments\", \"feedback\", \"review\", \"reviews\", \"ulasan\", \"cadangan\"]\n",
        "SENTIMENT_COL_CANDIDATES = [\"sentiment\", \"sentiment_label\"]\n",
        "LABEL_COL_CANDIDATES = [\"label\", \"labels\"]\n",
        "\n",
        "# If AUTO_DETECT_COLUMNS=False, set these manually:\n",
        "TEXT_COL = \"cadangan\"         # raw text column in Excel (example)\n",
        "SENTIMENT_COL = \"sentiment\"   # sentiment string column (positive/neutral/negative)\n",
        "LABEL_COL = \"label\"           # numeric label column (0,1,2)\n",
        "\n",
        "# -------------------------\n",
        "# Cleaning controls\n",
        "# -------------------------\n",
        "REMOVE_FILLER_COMMENTS = True\n",
        "\n",
        "# Training de-duplication (training stage only)\n",
        "# - \"none\": keep all rows\n",
        "# - \"by_text_label\": drop exact duplicates of (clean_text, label)  [recommended]\n",
        "# - \"by_text\": drop duplicates of clean_text only\n",
        "DEDUP_STRATEGY = \"by_text_label\"\n",
        "\n",
        "# -------------------------\n",
        "# Split ratios\n",
        "# -------------------------\n",
        "TRAIN_RATIO = 0.8\n",
        "VAL_RATIO = 0.1\n",
        "TEST_RATIO = 0.1\n",
        "SEED = 42\n",
        "\n",
        "# -------------------------\n",
        "# Model / training\n",
        "# -------------------------\n",
        "MODEL_NAME = \"xlm-roberta-base\"\n",
        "MAX_LEN = 256\n",
        "\n",
        "EPOCHS = 3\n",
        "TRAIN_BS = 16   # change to 8 if stuck\n",
        "EVAL_BS = 16    # change to 8 if stuck\n",
        "LEARNING_RATE = 2e-5\n",
        "WEIGHT_DECAY = 0.01\n",
        "\n",
        "EVAL_STEPS = 100      # change to 250 if bs = 8\n",
        "SAVE_STEPS = 200      # change to 500 if bs = 8\n",
        "LOGGING_STEPS = 100   # change to 250 if bs = 8\n",
        "EARLY_STOP_PATIENCE = 2\n",
        "\n",
        "# fp16 runs only if CUDA is available (safe auto)\n",
        "ENABLE_FP16 = True\n",
        "\n",
        "# -------------------------\n",
        "# Output paths\n",
        "# -------------------------\n",
        "OUT_TRAIN = \"/content/train_data.csv\"\n",
        "OUT_VAL   = \"/content/val_data.csv\"\n",
        "OUT_TEST  = \"/content/test_data.csv\"\n",
        "\n",
        "OUTPUT_DIR = \"/content/xlmr_results\"\n",
        "SAVE_DIR = \"/content/models/xlmr-base\"\n",
        "ZIP_OUT_PATH = \"/content/xlmr-base.zip\"\n",
        "\n",
        "EVAL_VAL_JSON = \"/content/eval_results_val.json\"\n",
        "EVAL_TEST_JSON = \"/content/eval_results_test.json\"\n",
        "CM_VAL_CSV = \"/content/confusion_matrix_val.csv\"\n",
        "CM_TEST_CSV = \"/content/confusion_matrix_test.csv\"\n",
        "REPORT_VAL_TXT = \"/content/classification_report_val.txt\"\n",
        "REPORT_TEST_TXT = \"/content/classification_report_test.txt\"\n",
        "TEST_PRED_CSV = \"/content/test_predictions.csv\""
      ],
      "metadata": {
        "id": "wGB99PkZCmT_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Dictionaries\n",
        "# Contraction correction dictionary\n",
        "contractions: Dict[str, str] = {\n",
        "    \"dont\": \"don't\",\n",
        "    \"doesnt\": \"doesn't\",\n",
        "    \"cant\": \"can't\",\n",
        "    \"wont\": \"won't\",\n",
        "    \"im\": \"I'm\",\n",
        "    \"ive\": \"I've\",\n",
        "    \"isnt\": \"isn't\",\n",
        "    \"arent\": \"aren't\",\n",
        "    \"wasnt\": \"wasn't\",\n",
        "    \"werent\": \"weren't\",\n",
        "    \"shouldnt\": \"shouldn't\",\n",
        "    \"couldnt\": \"couldn't\",\n",
        "    \"wouldnt\": \"wouldn't\",\n",
        "    \"didnt\": \"didn't\",\n",
        "    \"hadnt\": \"hadn't\",\n",
        "    \"hasnt\": \"hasn't\",\n",
        "    \"havent\": \"haven't\",\n",
        "    \"youre\": \"you're\",\n",
        "    \"theyre\": \"they're\",\n",
        "    \"thats\": \"that's\",\n",
        "    \"theres\": \"there's\",\n",
        "    \"whos\": \"who's\",\n",
        "    \"whats\": \"what's\",\n",
        "    \"ill\": \"I'll\",\n",
        "    \"youll\": \"you'll\",\n",
        "    \"theyll\": \"they'll\",\n",
        "    \"youve\": \"you've\",\n",
        "    \"weve\": \"we've\",\n",
        "}\n",
        "\n",
        "# Sentiment label encoding\n",
        "LABEL_ENCODING: Dict[str, int] = {\"positive\": 0, \"neutral\": 1, \"negative\": 2}\n",
        "ID2LABEL: Dict[int, str] = {v: k for k, v in LABEL_ENCODING.items()}\n",
        "\n",
        "# Filler/no-content comment pattern\n",
        "FILLER_PATTERN = r\"^\\s*(-|\\.|no\\.?|none|n/a|na|x|xde|no comment|not have|nothing|tak ada|takde cadangan|tak ada cadangan|tiada cadangan|x ada|xde komen|no suggestion|none suggestion)\\s*\\.?$\""
      ],
      "metadata": {
        "id": "Zg2tj9W2DMpK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Helper functions\n",
        "# A) Reproducibility\n",
        "def set_seed(seed: int) -> None:\n",
        "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    # Optional: more stable but slower\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "# B) Column detection\n",
        "def _pick_first_existing(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:\n",
        "    \"\"\"Pick the first existing column name in df.\"\"\"\n",
        "    lower_map = {c.lower(): c for c in df.columns}\n",
        "    for cand in candidates:\n",
        "        if cand.lower() in lower_map:\n",
        "            return lower_map[cand.lower()]\n",
        "    return None\n",
        "\n",
        "\n",
        "def detect_text_column(df: pd.DataFrame) -> str:\n",
        "    \"\"\"Detect ONLY the text column (Stage A: raw -> clean export).\"\"\"\n",
        "    if not AUTO_DETECT_COLUMNS:\n",
        "        return TEXT_COL\n",
        "\n",
        "    text_col = _pick_first_existing(df, TEXT_COL_CANDIDATES)\n",
        "    if text_col is None:\n",
        "        raise ValueError(\n",
        "            \"Could not detect a TEXT column.\\n\"\n",
        "            f\"Available columns: {list(df.columns)}\\n\"\n",
        "            f\"Expected something like: {TEXT_COL_CANDIDATES}\\n\"\n",
        "            \"Fix: set AUTO_DETECT_COLUMNS=False and set TEXT_COL manually.\"\n",
        "        )\n",
        "    return text_col\n",
        "\n",
        "\n",
        "def detect_columns(df: pd.DataFrame, require_label: bool = True) -> Tuple[str, Optional[str], Optional[str]]:\n",
        "    \"\"\"Detect text + (sentiment/label) columns for Stage B training.\"\"\"\n",
        "    if not AUTO_DETECT_COLUMNS:\n",
        "        return TEXT_COL, SENTIMENT_COL, LABEL_COL\n",
        "\n",
        "    text_col = _pick_first_existing(df, TEXT_COL_CANDIDATES)\n",
        "    sent_col = _pick_first_existing(df, SENTIMENT_COL_CANDIDATES)\n",
        "    lab_col = _pick_first_existing(df, LABEL_COL_CANDIDATES)\n",
        "\n",
        "    if text_col is None:\n",
        "        raise ValueError(\n",
        "            \"Could not detect a TEXT column.\\n\"\n",
        "            f\"Available columns: {list(df.columns)}\\n\"\n",
        "            f\"Expected something like: {TEXT_COL_CANDIDATES}\\n\"\n",
        "            \"Fix: set AUTO_DETECT_COLUMNS=False and set TEXT_COL manually.\"\n",
        "        )\n",
        "\n",
        "    if require_label and (sent_col is None and lab_col is None):\n",
        "        raise ValueError(\n",
        "            \"Could not detect SENTIMENT/LABEL columns.\\n\"\n",
        "            f\"Available columns: {list(df.columns)}\\n\"\n",
        "            f\"Expected sentiment like: {SENTIMENT_COL_CANDIDATES} or label like: {LABEL_COL_CANDIDATES}\\n\"\n",
        "            \"Fix: set AUTO_DETECT_COLUMNS=False and set SENTIMENT_COL or LABEL_COL manually.\"\n",
        "        )\n",
        "\n",
        "    return text_col, sent_col, lab_col\n",
        "\n",
        "\n",
        "# C) Text cleaning\n",
        "def fix_contractions(text: str) -> str:\n",
        "    \"\"\"Replace common missing-apostrophe contractions (whole words only).\"\"\"\n",
        "    for wrong, correct in contractions.items():\n",
        "        text = re.sub(r\"\\b\" + re.escape(wrong) + r\"\\b\", correct, text, flags=re.IGNORECASE)\n",
        "    return text\n",
        "\n",
        "\n",
        "def clean_text(text) -> str:\n",
        "    \"\"\"Clean and normalize ONE comment string.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Normalize Unicode to reduce weird variations\n",
        "    text = unicodedata.normalize(\"NFKC\", text)\n",
        "\n",
        "    # Remove leading Excel auto-insert characters (after stripping LEFT spaces)\n",
        "    if text.lstrip().startswith((\"=\", \"+\", \"-\")):\n",
        "        text = re.sub(r\"^\\s*[=+-]+\", \"\", text)\n",
        "\n",
        "    # Fix common contractions\n",
        "    text = fix_contractions(text)\n",
        "\n",
        "    # Normalize all variants of 'she course/subject' to a stable token\n",
        "    text = re.sub(r\"(['\\\"â€˜â€™]?)\\bshe\\b['\\\"â€˜â€™]?\\s+(course|subject)\", \"SHE_COURSE\", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\"\\bSHE (course|subject)\\b\", \"SHE_COURSE\", text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Normalize spacing\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "\n",
        "    # Keep basic punctuation; remove odd symbols\n",
        "    text = re.sub(r\"[^\\w\\s.,!?;:()\\'\\\"%><=/&+\\-]\", \"\", text)\n",
        "\n",
        "    # Trim whitespace\n",
        "    text = text.strip()\n",
        "\n",
        "    # Drop rows with no real content (only symbols / punctuation).\n",
        "    if not re.search(r\"[A-Za-z0-9\\u4e00-\\u9fff]\", text):\n",
        "        return \"\"\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def apply_dataset_cleaning(df: pd.DataFrame, text_col: str) -> pd.DataFrame:\n",
        "    \"\"\"Create 'clean_text' + remove blank/filler rows.\"\"\"\n",
        "    out = df.copy()\n",
        "    # Apply text cleaning function to the raw text column\n",
        "    out[\"clean_text\"] = out[text_col].apply(clean_text)\n",
        "\n",
        "    # Remove blank rows\n",
        "    out = out[out[\"clean_text\"].astype(str).str.strip() != \"\"].copy()\n",
        "\n",
        "    # Remove filler/no-content comments\n",
        "    if REMOVE_FILLER_COMMENTS:\n",
        "        out = out[~out[\"clean_text\"].str.lower().str.strip().str.match(FILLER_PATTERN)].copy()\n",
        "\n",
        "    return out.reset_index(drop=True)\n",
        "\n",
        "\n",
        "# D) Label validation\n",
        "def validate_and_build_label(df: pd.DataFrame, sent_col: Optional[str], lab_col: Optional[str]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Ensure df has numeric labels in {0,1,2} as column 'label'.\n",
        "    Supports:\n",
        "    - numeric label column OR\n",
        "    - sentiment string column (positive/neutral/negative) mapped using LABEL_ENCODING\n",
        "    \"\"\"\n",
        "    out = df.copy()\n",
        "\n",
        "    if lab_col is not None:\n",
        "        out[\"label\"] = pd.to_numeric(out[lab_col], errors=\"coerce\")\n",
        "        if out[\"label\"].isna().any():\n",
        "            bad = out.loc[out[\"label\"].isna(), lab_col].astype(str).unique().tolist()\n",
        "            raise ValueError(f\"Found non-numeric labels in '{lab_col}': {bad[:20]} (showing up to 20)\")\n",
        "        out[\"label\"] = out[\"label\"].astype(int)\n",
        "    else:\n",
        "        sent_norm = out[sent_col].astype(str).str.strip().str.lower()\n",
        "        out[\"label\"] = sent_norm.map(LABEL_ENCODING)\n",
        "        if out[\"label\"].isna().any():\n",
        "            bad = sorted(sent_norm[out[\"label\"].isna()].unique().tolist())\n",
        "            raise ValueError(\n",
        "                f\"Found unmapped sentiment values in '{sent_col}': {bad}\\n\"\n",
        "                f\"Expected only: {list(LABEL_ENCODING.keys())}\"\n",
        "            )\n",
        "        out[\"label\"] = out[\"label\"].astype(int)\n",
        "\n",
        "    valid = set(LABEL_ENCODING.values())\n",
        "    if not set(out[\"label\"].unique()).issubset(valid):\n",
        "        raise ValueError(f\"Invalid labels found. Expected subset of {valid}. Got: {sorted(out['label'].unique())}\")\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "# E) Dataset utilities (dedup, split, distributions)\n",
        "def deduplicate(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Optional de-duplication for training.\"\"\"\n",
        "    if DEDUP_STRATEGY == \"none\":\n",
        "        return df\n",
        "    if DEDUP_STRATEGY == \"by_text\":\n",
        "        return df.drop_duplicates(subset=[\"clean_text\"]).reset_index(drop=True)\n",
        "    if DEDUP_STRATEGY == \"by_text_label\":\n",
        "        return df.drop_duplicates(subset=[\"clean_text\", \"label\"]).reset_index(drop=True)\n",
        "    raise ValueError(f\"Unknown DEDUP_STRATEGY='{DEDUP_STRATEGY}'. Use: none/by_text/by_text_label\")\n",
        "\n",
        "\n",
        "def print_label_distribution(df: pd.DataFrame, title: str) -> None:\n",
        "    \"\"\"Print label distribution to spot imbalance quickly.\"\"\"\n",
        "    print(f\"\\n=== {title} ===\")\n",
        "    vc = df[\"label\"].value_counts().sort_index()\n",
        "    total = len(df)\n",
        "    for k, v in vc.items():\n",
        "        pct = (v / total) * 100 if total else 0.0\n",
        "        print(f\"label={k} ({ID2LABEL.get(int(k), 'unknown')}): {v} ({pct:.2f}%)\")\n",
        "    print(f\"Total rows: {total}\")\n",
        "\n",
        "\n",
        "def split_train_val_test(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Split into train/val/test (non-overlapping, stratified).\"\"\"\n",
        "    if not np.isclose(TRAIN_RATIO + VAL_RATIO + TEST_RATIO, 1.0):\n",
        "        raise ValueError(\"TRAIN_RATIO + VAL_RATIO + TEST_RATIO must sum to 1.0\")\n",
        "\n",
        "    df_small = df[[\"clean_text\", \"label\"]].reset_index(drop=True)\n",
        "\n",
        "    temp_ratio = VAL_RATIO + TEST_RATIO\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df_small,\n",
        "        test_size=temp_ratio,\n",
        "        random_state=SEED,\n",
        "        shuffle=True,\n",
        "        stratify=df_small[\"label\"],\n",
        "    )\n",
        "\n",
        "    test_within_temp = TEST_RATIO / temp_ratio\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=test_within_temp,\n",
        "        random_state=SEED,\n",
        "        shuffle=True,\n",
        "        stratify=temp_df[\"label\"],\n",
        "    )\n",
        "\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "\n",
        "# F) Output helpers (JSON + confusion matrix CSV)\n",
        "def save_json(path: str, obj: dict) -> None:\n",
        "    \"\"\"Save dict to JSON safely.\"\"\"\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(obj, f, indent=2)\n",
        "\n",
        "\n",
        "def save_confusion_matrix_csv(path: str, y_true: np.ndarray, y_pred: np.ndarray) -> None:\n",
        "    \"\"\"Save confusion matrix as CSV with readable row/col labels.\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    cm_df = pd.DataFrame(\n",
        "        cm,\n",
        "        index=[\"true_positive\", \"true_neutral\", \"true_negative\"],\n",
        "        columns=[\"pred_positive\", \"pred_neutral\", \"pred_negative\"],\n",
        "    )\n",
        "    cm_df.to_csv(path, encoding=\"utf-8-sig\", index=True)"
      ],
      "metadata": {
        "id": "ewPDF4yDDMYi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Stage A"
      ],
      "metadata": {
        "id": "ZpbUr9CAFrgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export cleaned Excel for annotation\n",
        "def export_cleaned_for_annotation() -> None:\n",
        "    \"\"\"RAW_INPUT_XLSX -> create clean_text -> export CLEANED_EXPORT_XLSX.\"\"\"\n",
        "    if not os.path.exists(RAW_INPUT_XLSX):\n",
        "        raise FileNotFoundError(\n",
        "            f\"File not found: {RAW_INPUT_XLSX}\\n\"\n",
        "            \"Upload raw_mixed_feedback.xlsx to /content/ (Colab) first.\"\n",
        "        )\n",
        "\n",
        "    df = pd.read_excel(RAW_INPUT_XLSX)\n",
        "    text_col = detect_text_column(df)\n",
        "\n",
        "    df_out = df.copy()\n",
        "    df_out[\"clean_text\"] = df_out[text_col].apply(clean_text)\n",
        "\n",
        "    # Remove blanks/filler before annotation (recommended)\n",
        "    df_out = df_out[df_out[\"clean_text\"].astype(str).str.strip() != \"\"].copy()\n",
        "    if REMOVE_FILLER_COMMENTS:\n",
        "        df_out = df_out[~df_out[\"clean_text\"].str.lower().str.strip().str.match(FILLER_PATTERN)].copy()\n",
        "\n",
        "    # Add an empty sentiment column if not present (makes annotation easier)\n",
        "    if not any(c.lower() == \"sentiment\" for c in df_out.columns):\n",
        "        df_out[\"sentiment\"] = \"\"\n",
        "\n",
        "    df_out.to_excel(CLEANED_EXPORT_XLSX, index=False)\n",
        "    print(f\"âœ… Exported cleaned file for annotation: {CLEANED_EXPORT_XLSX} (rows={len(df_out)})\")\n",
        "    print(\"\\nNext step:\")\n",
        "    print(\"1) Download clean_mixed_feedback.xlsx\")\n",
        "    print(\"2) Fill sentiment with: positive / neutral / negative\")\n",
        "    print(\"3) Save as labelled_mixed_feedback.xlsx and upload back to /content/\")\n",
        "\n",
        "# Run Stage A:\n",
        "export_cleaned_for_annotation()"
      ],
      "metadata": {
        "id": "AOgfNEiWDPa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e554e35-77fb-4b83-bbbf-70c469d1d8a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Exported cleaned file for annotation: /content/clean_mixed_feedback.xlsx (rows=9824)\n",
            "\n",
            "Next step:\n",
            "1) Download clean_mixed_feedback.xlsx\n",
            "2) Fill sentiment with: positive / neutral / negative\n",
            "3) Save as labelled_mixed_feedback.xlsx and upload back to /content/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Stage B"
      ],
      "metadata": {
        "id": "3ToJUPQQGyG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load labelled data\n",
        "def load_validate_clean_labelled() -> pd.DataFrame:\n",
        "    \"\"\"Load labelled Excel and ensure clean_text + label exist.\"\"\"\n",
        "    if not os.path.exists(LABELLED_INPUT_XLSX):\n",
        "        raise FileNotFoundError(\n",
        "            f\"File not found: {LABELLED_INPUT_XLSX}\\n\"\n",
        "            \"Upload labelled_mixed_feedback.xlsx to /content/ first.\"\n",
        "        )\n",
        "\n",
        "    df = pd.read_excel(LABELLED_INPUT_XLSX)\n",
        "\n",
        "    # If clean_text exists, reuse it to avoid mismatch vs your annotation.\n",
        "    has_clean_text = any(c.lower() == \"clean_text\" for c in df.columns)\n",
        "    if has_clean_text:\n",
        "        clean_col = next(c for c in df.columns if c.lower() == \"clean_text\")\n",
        "        text_col = clean_col\n",
        "        _, sent_col, lab_col = detect_columns(df, require_label=True)\n",
        "    else:\n",
        "        text_col, sent_col, lab_col = detect_columns(df, require_label=True)\n",
        "\n",
        "    # Build numeric label column\n",
        "    df = validate_and_build_label(df, sent_col=sent_col, lab_col=lab_col)\n",
        "\n",
        "    # Ensure clean_text exists + apply filtering\n",
        "    if not has_clean_text:\n",
        "        df = apply_dataset_cleaning(df, text_col=text_col)\n",
        "    else:\n",
        "        df = df.copy()\n",
        "        df[\"clean_text\"] = df[text_col].astype(str).str.strip()\n",
        "        df = df[df[\"clean_text\"] != \"\"].copy()\n",
        "        if REMOVE_FILLER_COMMENTS:\n",
        "            df = df[~df[\"clean_text\"].str.lower().str.strip().str.match(FILLER_PATTERN)].copy()\n",
        "        df = df.reset_index(drop=True)\n",
        "\n",
        "    # De-duplication (training-only convenience)\n",
        "    df = deduplicate(df)\n",
        "\n",
        "    print(f\"âœ… Loaded labelled dataset: rows={len(df)}\")\n",
        "    # Note: label ids follow LABEL_ENCODING = {\"positive\": 0, \"neutral\": 1, \"negative\": 2}\n",
        "    print_label_distribution(df, \"Full labelled dataset distribution\")\n",
        "    return df\n",
        "\n",
        "df_labelled = load_validate_clean_labelled()\n",
        "df_labelled.head()"
      ],
      "metadata": {
        "id": "NurW9WgZDPRQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "51bbd701-1008-437e-b176-759f971ff997"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded labelled dataset: rows=5012\n",
            "\n",
            "=== Full labelled dataset distribution ===\n",
            "label=0 (positive): 1889 (37.69%)\n",
            "label=1 (neutral): 2013 (40.16%)\n",
            "label=2 (negative): 1110 (22.15%)\n",
            "Total rows: 5012\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  course_code                 course_name  occ  \\\n",
              "0     ACC 610  Public Accounting Practice    2   \n",
              "1     ACC 611          External Reporting    2   \n",
              "2     ACC 623     Business Technology Law    2   \n",
              "3     ACC 650    Assurance and Governance    2   \n",
              "4     ACC 685      Performance Management    1   \n",
              "\n",
              "                                             reviews  \\\n",
              "0  Saya rasa kursus ini berguna dari segi strateg...   \n",
              "1  This course is like AFM291, 391, and 491 on st...   \n",
              "2  Saya gagal melihat bagaimana kursus ini sesuai...   \n",
              "3  In our year, the lectures were mostly designed...   \n",
              "4  Jika anda fikir AFM433 adalah mengarut (bs), m...   \n",
              "\n",
              "                                          clean_text sentiment  label  \n",
              "0  Saya rasa kursus ini berguna dari segi strateg...   neutral      1  \n",
              "1  This course is like AFM291, 391, and 491 on st...   neutral      1  \n",
              "2  Saya gagal melihat bagaimana kursus ini sesuai...  negative      2  \n",
              "3  In our year, the lectures were mostly designed...  positive      0  \n",
              "4  Jika anda fikir AFM433 adalah mengarut (bs), m...  negative      2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e90d0fb0-9497-4a31-b9a2-6739194dac30\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>course_code</th>\n",
              "      <th>course_name</th>\n",
              "      <th>occ</th>\n",
              "      <th>reviews</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ACC 610</td>\n",
              "      <td>Public Accounting Practice</td>\n",
              "      <td>2</td>\n",
              "      <td>Saya rasa kursus ini berguna dari segi strateg...</td>\n",
              "      <td>Saya rasa kursus ini berguna dari segi strateg...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ACC 611</td>\n",
              "      <td>External Reporting</td>\n",
              "      <td>2</td>\n",
              "      <td>This course is like AFM291, 391, and 491 on st...</td>\n",
              "      <td>This course is like AFM291, 391, and 491 on st...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ACC 623</td>\n",
              "      <td>Business Technology Law</td>\n",
              "      <td>2</td>\n",
              "      <td>Saya gagal melihat bagaimana kursus ini sesuai...</td>\n",
              "      <td>Saya gagal melihat bagaimana kursus ini sesuai...</td>\n",
              "      <td>negative</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ACC 650</td>\n",
              "      <td>Assurance and Governance</td>\n",
              "      <td>2</td>\n",
              "      <td>In our year, the lectures were mostly designed...</td>\n",
              "      <td>In our year, the lectures were mostly designed...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ACC 685</td>\n",
              "      <td>Performance Management</td>\n",
              "      <td>1</td>\n",
              "      <td>Jika anda fikir AFM433 adalah mengarut (bs), m...</td>\n",
              "      <td>Jika anda fikir AFM433 adalah mengarut (bs), m...</td>\n",
              "      <td>negative</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e90d0fb0-9497-4a31-b9a2-6739194dac30')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e90d0fb0-9497-4a31-b9a2-6739194dac30 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e90d0fb0-9497-4a31-b9a2-6739194dac30');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_labelled",
              "summary": "{\n  \"name\": \"df_labelled\",\n  \"rows\": 5012,\n  \"fields\": [\n    {\n      \"column\": \"course_code\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 807,\n        \"samples\": [\n          \"ENVS 201\",\n          \"CHEM 265L\",\n          \"BME 261\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"course_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 753,\n        \"samples\": [\n          \"Fluvial Geomorphology\",\n          \"Introduction to Canadian Environmental Law\",\n          \"Project Management\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"occ\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviews\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5012,\n        \"samples\": [\n          \"Everything is trivial.\",\n          \"I did it in the last couple of terms it was offered cause I had to do it, hella easy. No need to worry at all y'all, I can't say about the Lab Final though cause it was cancelled for COVID.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5012,\n        \"samples\": [\n          \"Everything is trivial.\",\n          \"I did it in the last couple of terms it was offered cause I had to do it, hella easy. No need to worry at all y'all, I can't say about the Lab Final though cause it was cancelled for COVID.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"neutral\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train/val/test and save CSVs\n",
        "train_df, val_df, test_df = split_train_val_test(df_labelled)\n",
        "\n",
        "# Save to CSV (so you can reuse without re-reading Excel)\n",
        "train_df.to_csv(OUT_TRAIN, index=False, encoding=\"utf-8-sig\")\n",
        "val_df.to_csv(OUT_VAL, index=False, encoding=\"utf-8-sig\")\n",
        "test_df.to_csv(OUT_TEST, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"âœ… Saved:\")\n",
        "print(f\" - {OUT_TRAIN} (rows={len(train_df)})\")\n",
        "print(f\" - {OUT_VAL}   (rows={len(val_df)})\")\n",
        "print(f\" - {OUT_TEST}  (rows={len(test_df)})\")\n",
        "\n",
        "print_label_distribution(train_df, \"Train distribution\")\n",
        "print_label_distribution(val_df, \"Val distribution\")\n",
        "print_label_distribution(test_df, \"Test distribution\")"
      ],
      "metadata": {
        "id": "HNJMbO94DOrJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6117ba85-16a1-4c18-ab7c-4c9268ff3693"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved:\n",
            " - /content/train_data.csv (rows=4009)\n",
            " - /content/val_data.csv   (rows=501)\n",
            " - /content/test_data.csv  (rows=502)\n",
            "\n",
            "=== Train distribution ===\n",
            "label=0 (positive): 1511 (37.69%)\n",
            "label=1 (neutral): 1610 (40.16%)\n",
            "label=2 (negative): 888 (22.15%)\n",
            "Total rows: 4009\n",
            "\n",
            "=== Val distribution ===\n",
            "label=0 (positive): 189 (37.72%)\n",
            "label=1 (neutral): 201 (40.12%)\n",
            "label=2 (negative): 111 (22.16%)\n",
            "Total rows: 501\n",
            "\n",
            "=== Test distribution ===\n",
            "label=0 (positive): 189 (37.65%)\n",
            "label=1 (neutral): 202 (40.24%)\n",
            "label=2 (negative): 111 (22.11%)\n",
            "Total rows: 502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) Stage C"
      ],
      "metadata": {
        "id": "EWEuqwgiv5Xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Dataset + Train (XLM-R Trainer)\n",
        "class SentimentDataset(Dataset):\n",
        "    \"\"\"Torch dataset; dynamic padding is handled by DataCollatorWithPadding.\"\"\"\n",
        "    def __init__(self, df: pd.DataFrame, tokenizer, max_length: int = 256):\n",
        "        self.texts = df[\"clean_text\"].astype(str).tolist()\n",
        "        self.labels = df[\"label\"].astype(int).tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> dict:\n",
        "        encoded = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "        )\n",
        "        encoded[\"labels\"] = int(self.labels[idx])\n",
        "        return encoded\n",
        "\n",
        "\n",
        "def train_model(train_df: pd.DataFrame, val_df: pd.DataFrame) -> Trainer:\n",
        "    \"\"\"Train XLM-R using train_df and validate on val_df.\"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(LABEL_ENCODING))\n",
        "\n",
        "    # Store label mappings in config (helps safe save/load later)\n",
        "    model.config.label2id = LABEL_ENCODING\n",
        "    model.config.id2label = ID2LABEL\n",
        "\n",
        "    train_ds = SentimentDataset(train_df, tokenizer, max_length=MAX_LEN)\n",
        "    val_ds = SentimentDataset(val_df, tokenizer, max_length=MAX_LEN)\n",
        "\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    accuracy = evaluate.load(\"accuracy\")\n",
        "    f1 = evaluate.load(\"f1\")\n",
        "\n",
        "    def compute_metrics(eval_pred):\n",
        "        \"\"\"Compute accuracy + weighted F1 + macro F1.\"\"\"\n",
        "        logits, labels = eval_pred\n",
        "        preds = np.argmax(logits, axis=-1)\n",
        "        acc = accuracy.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
        "        f1_weighted = f1.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"]\n",
        "        f1_macro = f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
        "        return {\"accuracy\": acc, \"f1\": f1_weighted, \"f1_macro\": f1_macro}\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        num_train_epochs=EPOCHS,\n",
        "        per_device_train_batch_size=TRAIN_BS,\n",
        "        per_device_eval_batch_size=EVAL_BS,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        weight_decay=WEIGHT_DECAY,\n",
        "\n",
        "        eval_strategy=\"steps\",\n",
        "        save_strategy=\"steps\",\n",
        "        eval_steps=EVAL_STEPS,\n",
        "        save_steps=SAVE_STEPS,\n",
        "        logging_steps=LOGGING_STEPS,\n",
        "\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1_macro\",\n",
        "        greater_is_better=True,\n",
        "\n",
        "        save_total_limit=2,\n",
        "        seed=SEED,\n",
        "\n",
        "        # No external trackers\n",
        "        report_to=\"none\",\n",
        "\n",
        "        # Safe auto fp16\n",
        "        fp16=(ENABLE_FP16 and torch.cuda.is_available()),\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_ds,\n",
        "        eval_dataset=val_ds,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=EARLY_STOP_PATIENCE)],\n",
        "    )\n",
        "\n",
        "    print(\"CUDA available:\", torch.cuda.is_available())\n",
        "    print(\"fp16 enabled:\", (ENABLE_FP16 and torch.cuda.is_available()))\n",
        "    print(\"\\nðŸš€ Training started...\")\n",
        "    trainer.train()\n",
        "    print(\"âœ… Training finished.\")\n",
        "    return trainer\n",
        "\n",
        "set_seed(SEED)\n",
        "trainer = train_model(train_df, val_df)"
      ],
      "metadata": {
        "id": "WboZQDHqHlfN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "03362943-bfe6-4c39-c577-4a2cf32beb6b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-495560898.py:77: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "fp16 enabled: True\n",
            "\n",
            "ðŸš€ Training started...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='753' max='753' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [753/753 15:43, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.041200</td>\n",
              "      <td>0.847550</td>\n",
              "      <td>0.594810</td>\n",
              "      <td>0.569691</td>\n",
              "      <td>0.546659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.765000</td>\n",
              "      <td>0.629103</td>\n",
              "      <td>0.710579</td>\n",
              "      <td>0.705671</td>\n",
              "      <td>0.694005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.620100</td>\n",
              "      <td>0.618379</td>\n",
              "      <td>0.742515</td>\n",
              "      <td>0.739892</td>\n",
              "      <td>0.741213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.537000</td>\n",
              "      <td>0.613898</td>\n",
              "      <td>0.756487</td>\n",
              "      <td>0.751770</td>\n",
              "      <td>0.758087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.531300</td>\n",
              "      <td>0.541060</td>\n",
              "      <td>0.792415</td>\n",
              "      <td>0.789238</td>\n",
              "      <td>0.791467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.410200</td>\n",
              "      <td>0.519680</td>\n",
              "      <td>0.810379</td>\n",
              "      <td>0.808470</td>\n",
              "      <td>0.810382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.367500</td>\n",
              "      <td>0.579042</td>\n",
              "      <td>0.796407</td>\n",
              "      <td>0.794693</td>\n",
              "      <td>0.792763</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Training finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Global steps:\", trainer.state.global_step)\n",
        "print(\"Max steps:\", trainer.state.max_steps)\n",
        "print(\"Best checkpoint:\", trainer.state.best_model_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJuXc_VzXv9Y",
        "outputId": "54e6418c-fd90-4d30-87c4-123e8009254d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global steps: 753\n",
            "Max steps: 753\n",
            "Best checkpoint: /content/xlmr_results/checkpoint-600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate (VAL + TEST) and save reports\n",
        "def evaluate_and_save(trainer: Trainer, df_eval: pd.DataFrame, split_name: str,\n",
        "                      out_json: str, out_cm_csv: str, out_report_txt: str) -> None:\n",
        "    \"\"\"Evaluate on a split and save JSON + confusion matrix + classification report.\"\"\"\n",
        "    eval_ds = SentimentDataset(df_eval, trainer.tokenizer, max_length=MAX_LEN)\n",
        "\n",
        "    eval_results = trainer.evaluate(eval_dataset=eval_ds)\n",
        "    print(f\"\\nðŸ“Š {split_name} evaluation results:\")\n",
        "    for k, v in eval_results.items():\n",
        "        try:\n",
        "            print(f\"{k}: {float(v):.4f}\")\n",
        "        except Exception:\n",
        "            print(f\"{k}: {v}\")\n",
        "\n",
        "    pred = trainer.predict(eval_ds)\n",
        "    y_true = pred.label_ids\n",
        "    y_pred = np.argmax(pred.predictions, axis=1)\n",
        "\n",
        "    save_json(out_json, {k: (float(v) if isinstance(v, (int, float, np.floating)) else v) for k, v in eval_results.items()})\n",
        "    save_confusion_matrix_csv(out_cm_csv, y_true, y_pred)\n",
        "\n",
        "    report_txt = classification_report(y_true, y_pred, target_names=[\"positive\", \"neutral\", \"negative\"])\n",
        "    with open(out_report_txt, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(report_txt)\n",
        "\n",
        "    print(f\"âœ… Saved: {out_json}\")\n",
        "    print(f\"âœ… Saved: {out_cm_csv}\")\n",
        "    print(f\"âœ… Saved: {out_report_txt}\")\n",
        "\n",
        "\n",
        "def save_test_predictions(trainer: Trainer, test_df: pd.DataFrame) -> None:\n",
        "    \"\"\"Export test predictions CSV (true label + predicted label + confidence).\"\"\"\n",
        "    test_ds = SentimentDataset(test_df, trainer.tokenizer, max_length=MAX_LEN)\n",
        "\n",
        "    pred = trainer.predict(test_ds)\n",
        "    logits = pred.predictions\n",
        "    y_true = pred.label_ids\n",
        "    y_pred = np.argmax(logits, axis=1)\n",
        "\n",
        "    probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
        "    max_prob = probs.max(axis=1)\n",
        "\n",
        "    out = test_df.copy()\n",
        "    out[\"true_sentiment\"] = [ID2LABEL[int(i)] for i in y_true]\n",
        "    out[\"pred_label\"] = y_pred.astype(int)\n",
        "    out[\"pred_sentiment\"] = [ID2LABEL[int(i)] for i in y_pred]\n",
        "    out[\"pred_confidence\"] = max_prob\n",
        "\n",
        "    out.to_csv(TEST_PRED_CSV, index=False, encoding=\"utf-8-sig\")\n",
        "    print(f\"âœ… Saved test predictions: {TEST_PRED_CSV} (rows={len(out)})\")\n",
        "\n",
        "\n",
        "# Evaluate & save\n",
        "evaluate_and_save(trainer, val_df,  \"VAL\",  EVAL_VAL_JSON,  CM_VAL_CSV,  REPORT_VAL_TXT)\n",
        "evaluate_and_save(trainer, test_df, \"TEST\", EVAL_TEST_JSON, CM_TEST_CSV, REPORT_TEST_TXT)\n",
        "\n",
        "# Save detailed test predictions\n",
        "save_test_predictions(trainer, test_df)"
      ],
      "metadata": {
        "id": "S2eG1oM2HlSD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "84180503-88a9-44df-8c7c-36a0dab99d04"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š VAL evaluation results:\n",
            "eval_loss: 0.5197\n",
            "eval_accuracy: 0.8104\n",
            "eval_f1: 0.8085\n",
            "eval_f1_macro: 0.8104\n",
            "eval_runtime: 1.3582\n",
            "eval_samples_per_second: 368.8590\n",
            "eval_steps_per_second: 23.5600\n",
            "epoch: 3.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: /content/eval_results_val.json\n",
            "âœ… Saved: /content/confusion_matrix_val.csv\n",
            "âœ… Saved: /content/classification_report_val.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š TEST evaluation results:\n",
            "eval_loss: 0.4812\n",
            "eval_accuracy: 0.8088\n",
            "eval_f1: 0.8073\n",
            "eval_f1_macro: 0.8117\n",
            "eval_runtime: 1.4319\n",
            "eval_samples_per_second: 350.5870\n",
            "eval_steps_per_second: 22.3480\n",
            "epoch: 3.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: /content/eval_results_test.json\n",
            "âœ… Saved: /content/confusion_matrix_test.csv\n",
            "âœ… Saved: /content/classification_report_test.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved test predictions: /content/test_predictions.csv (rows=502)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model + zip\n",
        "def save_model_and_zip(trainer: Trainer) -> None:\n",
        "    \"\"\"Save model/tokenizer, zip it, and download if running in Colab.\"\"\"\n",
        "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "    trainer.tokenizer.save_pretrained(SAVE_DIR)\n",
        "    trainer.save_model(SAVE_DIR)\n",
        "    print(f\"âœ… Model saved to: {SAVE_DIR}\")\n",
        "\n",
        "    base_no_ext = ZIP_OUT_PATH.replace(\".zip\", \"\")\n",
        "    shutil.make_archive(base_no_ext, \"zip\", SAVE_DIR)\n",
        "    print(f\"âœ… Model zipped to: {ZIP_OUT_PATH}\")\n",
        "\n",
        "    # Colab download helper\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(ZIP_OUT_PATH)\n",
        "    except Exception:\n",
        "        print(\"Note: files.download works only in Google Colab (safe to ignore).\")\n",
        "\n",
        "save_model_and_zip(trainer)"
      ],
      "metadata": {
        "id": "JOuHoH7iHlO8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "614d78b5-2d2b-42d9-b643-69262346ee52"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model saved to: /content/models/xlmr-base\n",
            "âœ… Model zipped to: /content/xlmr-base.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9e763211-f4ec-4f1f-a865-834395afdafb\", \"xlmr-base.zip\", 833516310)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}